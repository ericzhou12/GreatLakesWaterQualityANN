{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from scipy import stats\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# read datasets, data taken from public csv from the EPA and NCCA\n",
    "# original df is https://www.epa.gov/sites/default/files/2021-04/ncca_2015_water_chemistry_great_lakes-data.csv\n",
    "# df for secchi disks (SD) is found here https://www.epa.gov/system/files/other-files/2023-02/Final%20NCCA%20GL%20Special%20Study%20%282014-2018%29%20data%20and%20metadata.zip \n",
    "# df for dissolved oxygen (DO) is in the same site\n",
    "df = pd.read_csv(\"ncca_2015_water_chemistry_great_lakes-data.csv\")\n",
    "dfSD = pd.read_csv(\"ncca_2014-2018_secchi_great_lakes_special_study_data.csv\")\n",
    "dfDO = pd.read_csv(\"ncca_2014-2018_hydrographic_profile_great_lakes_special_study_data.csv\")\n",
    "\n",
    "# data is split into 4 batches to allow for 3 epochs to train the model and then 1 to test the accuracy\n",
    "\n",
    "# non-TSI but important variables\n",
    "\n",
    "# pH readings\n",
    "pHList = [[], [], [], []]\n",
    "pHAvg = [0] * 4\n",
    "df = df.dropna(subset=['RESULT'])\n",
    "for index, row in df.loc[df['ANALYTE'] == \"PH\"].iterrows():\n",
    "    day, month, yr = row['DATE_COL'].split(\"-\")\n",
    "    # data starts from June and goes to Sep\n",
    "    if month == 'Jun':\n",
    "        pHList[0].append(row['RESULT'])\n",
    "    elif month == 'Jul':\n",
    "        pHList[1].append(row['RESULT'])\n",
    "    elif month == 'Aug':\n",
    "        pHList[2].append(row['RESULT'])\n",
    "    else:\n",
    "        pHList[3].append(row['RESULT'])\n",
    "for t, i in enumerate(pHList):\n",
    "    pHAvg[t] = sum(i)/(len(i))\n",
    "\n",
    "# dissolved oxygen (DO) readings\n",
    "DOList = [[], [], [], []]\n",
    "DOAvg = [0] * 4\n",
    "dfDO = dfDO.dropna(subset=['DO'])\n",
    "for index, row in dfDO.loc[dfDO['STUDY'] == \"Lake_Erie_Study\"].iterrows():\n",
    "    day, month, yr = row['DATE_COL'].split(\"-\")\n",
    "    # data starts from June and goes to Sep\n",
    "    if month == 'Jun':\n",
    "        DOList[0].append(row['DO'])\n",
    "    elif month == 'Jul':\n",
    "        DOList[1].append(row['DO'])\n",
    "    elif month == 'Aug':\n",
    "        DOList[2].append(row['DO'])\n",
    "    else:\n",
    "        DOList[3].append(row['DO'])\n",
    "for t, i in enumerate(DOList):\n",
    "    DOAvg[t] = sum(i)/(len(i))\n",
    "\n",
    "# TSI variables\n",
    "\n",
    "# Chlorophyll A (CHLA) readings \n",
    "CHLAList = [[], [], [], []]\n",
    "CHLA_Avg = [0] * 4\n",
    "for index, row in df.loc[df['ANALYTE'] == \"CHLA\"].iterrows():\n",
    "    day, month, yr = row['DATE_COL'].split(\"-\")\n",
    "    # data starts from June and goes to Sep\n",
    "    if month == 'Jun':\n",
    "        CHLAList[0].append(row['RESULT'])\n",
    "    elif month == 'Jul':\n",
    "        CHLAList[1].append(row['RESULT'])\n",
    "    elif month == 'Aug':\n",
    "        CHLAList[2].append(row['RESULT'])\n",
    "    else:\n",
    "        CHLAList[3].append(row['RESULT'])\n",
    "for t, i in enumerate(CHLAList):\n",
    "    CHLA_Avg[t] = sum(i)/(len(i))\n",
    "\n",
    "# Secchi Disk (SD) readings\n",
    "# Secchi Disk Depth is the depth when the disk disappears and measures turbidity\n",
    "SDList = [[], [], [], []]\n",
    "SDAvg = [0] * 4\n",
    "dfSD = dfSD.dropna(subset=['DISAPPEARS'])\n",
    "for index, row in dfSD.loc[dfSD['STUDY'] == \"Lake_Erie_Study\"].iterrows():\n",
    "    day, month, yr = row['DATE_COL'].split(\"-\")\n",
    "    # data starts from June and goes to Sep\n",
    "    if month == 'Jun':\n",
    "        SDList[0].append(row['DISAPPEARS'])\n",
    "    elif month == 'Jul':\n",
    "        SDList[1].append(row['DISAPPEARS'])\n",
    "    elif month == 'Aug':\n",
    "        SDList[2].append(row['DISAPPEARS'])\n",
    "    else:\n",
    "        SDList[3].append(row['DISAPPEARS'])\n",
    "for t, i in enumerate(SDList):\n",
    "    SDAvg[t] = sum(i)/(len(i))\n",
    "\n",
    "# Total Phosphorus (TP) readings \n",
    "TPList = [[], [], [], []]\n",
    "TPAvg = [0] * 4\n",
    "for index, row in df.loc[df['ANALYTE'] == \"PTL\"].iterrows():\n",
    "    day, month, yr = row['DATE_COL'].split(\"-\")\n",
    "    # data starts from June and goes to Sep\n",
    "    if month == 'Jun':\n",
    "        TPList[0].append(row['RESULT'])\n",
    "    elif month == 'Jul':\n",
    "        TPList[1].append(row['RESULT'])\n",
    "    elif month == 'Aug':\n",
    "        TPList[2].append(row['RESULT'])\n",
    "    else:\n",
    "        TPList[3].append(row['RESULT'])\n",
    "for t, i in enumerate(TPList):\n",
    "    TPAvg[t] = sum(i)/(len(i))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 70.6052\n",
      "Epoch [11/100], Loss: 40.9567\n",
      "Epoch [21/100], Loss: 42.6045\n",
      "Epoch [31/100], Loss: 37.6237\n",
      "Epoch [41/100], Loss: 0.9197\n",
      "Epoch [51/100], Loss: 3.4652\n",
      "Epoch [61/100], Loss: 0.1738\n",
      "Epoch [71/100], Loss: 0.3046\n",
      "Epoch [81/100], Loss: 0.0545\n",
      "Epoch [91/100], Loss: 0.0385\n",
      "Epoch [1/100], Loss: 0.3150\n",
      "Epoch [11/100], Loss: 0.0080\n",
      "Epoch [21/100], Loss: 0.0302\n",
      "Epoch [31/100], Loss: 0.0051\n",
      "Epoch [41/100], Loss: 0.0023\n",
      "Epoch [51/100], Loss: 0.0016\n",
      "Epoch [61/100], Loss: 0.0001\n",
      "Epoch [71/100], Loss: 0.0002\n",
      "Epoch [81/100], Loss: 0.0000\n",
      "Epoch [91/100], Loss: 0.0000\n",
      "Epoch [1/100], Loss: 0.1819\n",
      "Epoch [11/100], Loss: 0.0135\n",
      "Epoch [21/100], Loss: 0.0084\n",
      "Epoch [31/100], Loss: 0.0073\n",
      "Epoch [41/100], Loss: 0.0007\n",
      "Epoch [51/100], Loss: 0.0001\n",
      "Epoch [61/100], Loss: 0.0003\n",
      "Epoch [71/100], Loss: 0.0001\n",
      "Epoch [81/100], Loss: 0.0000\n",
      "Epoch [91/100], Loss: 0.0000\n",
      "Prediction: tensor([[7.7433, 8.4874]])\n",
      "tensor([8.0552, 8.8082]) tensor([[7.7433, 8.4874]])\n",
      "tensor(0.1001)\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "class neuralnet(nn.Module):\n",
    "    def __init__(self, insize, hiddensize, outsize):\n",
    "        super(neuralnet, self).__init__()\n",
    "        self.hidden = nn.Linear(insize, hiddensize)\n",
    "        self.output = nn.Linear(hiddensize, outsize)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        x = self.sigmoid(self.hidden(x))\n",
    "        x = self.relu(self.output(x))\n",
    "        return x\n",
    "    \n",
    "\n",
    "# avgs\n",
    "def avg(x):\n",
    "    for t, i in enumerate(x):\n",
    "        x[t] = sum(i)/len(i)\n",
    "\n",
    "\n",
    "# train data\n",
    "xtrain = [[CHLA_Avg[0], TPAvg[0], SDAvg[0]], [CHLA_Avg[1], TPAvg[1], SDAvg[1]], [CHLA_Avg[2], TPAvg[2], SDAvg[2]]] #3x3 matrix, 3 samples 3 inputs (CHLA, TP, SD)\n",
    "ytrain = [[pHAvg[0], DOAvg[0]], [pHAvg[1], DOAvg[1]], [pHAvg[2], DOAvg[2]]]#3x2 matrix, 3 samples 2 outputs (pH, DO)\n",
    "xtrain = torch.tensor(xtrain)\n",
    "ytrain = torch.tensor(ytrain)\n",
    "\n",
    "# sizes\n",
    "insize = 3\n",
    "hiddensize = 128\n",
    "outsize = 2\n",
    "\n",
    "model = neuralnet(insize, hiddensize, outsize)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# training\n",
    "for i in range(len(xtrain)):\n",
    "    epochs = 100\n",
    "    for e in range(epochs):\n",
    "        model.train()\n",
    "        outputs = model(xtrain[i])\n",
    "        loss = criterion(outputs, ytrain[i])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if e%10 == 0:    \n",
    "            print(f'Epoch [{e+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# predictions\n",
    "testSet = [[CHLA_Avg[3], TPAvg[3], SDAvg[3]]]\n",
    "testSet = torch.tensor(testSet)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    prediction = model(testSet)\n",
    "    print(\"Prediction:\", prediction)\n",
    "\n",
    "# error calculation\n",
    "ans = [pHAvg[3], DOAvg[3]]\n",
    "ans = torch.tensor(ans)\n",
    "MSE = np.square(np.subtract(ans, prediction)).mean()\n",
    "print(ans, prediction)\n",
    "print(MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graphs\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
